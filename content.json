{"pages":[{"title":"","date":"2017-02-23T05:59:20.000Z","updated":"2017-02-23T05:59:20.000Z","comments":true,"path":"baidu_verify_6CUBSjOkjO.html","permalink":"http://www.sun4lower.cn/baidu_verify_6CUBSjOkjO.html","excerpt":"","text":"6CUBSjOkjO"},{"title":"","date":"2017-02-23T07:22:51.000Z","updated":"2017-02-23T07:22:50.000Z","comments":true,"path":"google08b22fddddb90dee.html","permalink":"http://www.sun4lower.cn/google08b22fddddb90dee.html","excerpt":"","text":"google-site-verification: google08b22fddddb90dee.html"}],"posts":[{"title":"Spark RPC 到底是个什么鬼？","slug":"SparkRpcBasic","date":"2017-02-22T09:49:24.000Z","updated":"2017-02-24T07:49:21.000Z","comments":true,"path":"2017/02/22/SparkRpcBasic/","link":"","permalink":"http://www.sun4lower.cn/2017/02/22/SparkRpcBasic/","excerpt":"","text":"本文会为大家介绍Spark中的RPC通信机制，详细阐述“Spark RPC到底是个什么鬼？”，闲话少叙，让我们来进入Spark RPC的世界！ Spark RPC三剑客Spark RPC中最为重要的三个抽象（“三剑客”）为：RpcEnv、RpcEndpoint、RpcEndpointRef，这样做的好处有： 对上层的API来说，屏蔽了底层的具体实现，使用方便 可以通过不同的实现来完成指定的功能，方便扩展 促进了底层实现层的良性竞争，Spark 1.6.3中默认使用了Netty作为底层的实现，但Akka的依赖依然存在；而Spark 2.1.0中的底层实现只有Netty，这样用户可以方便的使用不同版本的Akka或者将来某种更好的底层实现 下面我们就结合Netty和“三剑客”来具体分析他们是如何来协同工作的。 Send a message locally我们通过Spark源码中的一个Test（RpcEnvSuite.scala）来分析一下发送本地消息的具体流程，源码如下（对源码做了一些修改）： 12345678910111213141516test(\"send a message locally\") &#123; @volatile var message: String = null val rpcEndpointRef = env.setupEndpoint(\"send-locally\", new RpcEndpoint &#123; override val rpcEnv = env override def receive = &#123; //case msg: String =&gt; message = msg case msg: String =&gt; println(message) //我们直接将接收到的消息打印出来 &#125; &#125;) rpcEndpointRef.send(\"hello\") //下面是原来的代码 //eventually(timeout(5 seconds), interval(10 millis)) &#123; // assert(\"hello\" === message) //&#125;&#125; 为了方便理解，先把流程图贴出来，然后详细进行阐述： 下面我们来详细阐述上例的具体过程： 首先是RpcEndpoint创建并注册的流程：（图中的蓝色线条部分） 1、创建RpcEndpoint，并初始化rpcEnv的引用（RpcEnv已经创建好，底层实际上是实例化了一个NettyRpcEnv，而NettyRpcEnv是通过工厂方法NettyRpcEnvFactory创建的） 2、实例化RpcEndpoint之后需要向RpcEnv注册该RpcEndpoint，底层实现是向NettyRpcEnv进行注册，而实际上是通过调用Dispatcher的registerRpcEndpoint方法向Dispatcher进行注册 3、具体的注册就是向endpoints、endpointRefs、receivers中插入记录：而receivers中插入的信息会被Dispatcher中的线程池中的线程执行：会将记录take出来然后调用Inbox的process方法通过模式匹配的方法进行处理，注册的时候通过匹配到OnStart类型的message，去执行RpcEndpoint的onStart方法（例如Master、Worker注册时，就要执行各自的onStart方法），本例中未做任何操作 4、注册完成后返回RpcEndpointRef，我们通过RpcEndpointRef就可以向其代表的RpcEndpoint发送消息 下面就是通过RpcEndpointRef向其代表的RpcEndpoint发送消息的具体流程：（图中的红色线条部分） 1、2、调用RpcEndpointRef的send方法，底层实现是调用Netty的NettyRpcEndpointRef的send方法，而实际上又是调用的NettyRpcEnv的send方法，发送的消息使用RequestMessage进行封装： 1nettyEnv.send(RequestMessage(nettyEnv.address, this, message)) 3、4、NettyRpcEnv的send方法首先会根据RpcAddress判断是本地还是远程调用，此处是同一个RpcEnv，所以是本地调用，即调用Dispatcher的postOneWayMessage方法 5、postOneWayMessage方法内部调用Dispatcher的postMessage方法 6、postMessage会向具体的RpcEndpoint发送消息，首先通过endpointName从endpoints中获得注册时的EndpointData，如果不为空就执行EndpointData中Inbox的post(message)方法，向Inbox的mesages中插入一条InboxMessage，同时向receivers中插入一条记录，此处将Inbox单独画出来是为了方便大家理解 7、Dispatcher中的线程池会拿出一条线程用来循环receivers中的消息，首先使用take方法获得receivers中的一条记录，然后调用Inbox的process方法来执行这条记录，而process将messages中的一条InboxMessage（第6步中插入的）拿出来进行处理，具体的处理方法就是通过模式匹配的方法，匹配到消息的类型（此处是OneWayMessage），然后来执行RpcEndpoint中对应的receive方法，在此例中我们只打印出这条消息（步骤8） 至此，一个简单的发送本地消息的流程执行完成。 什么，上面的图太复杂了？我也觉得，下面给出一张简洁的图： 我们通过NettyRpcEndpointRef来发出一个消息，消息经过NettyRpcEnv、Dispatcher、Inbox的共同处理最终将消息发送到NettyRpcEndpoint，NettyRpcEndpoint收到消息后进行处理（一般是通过模式匹配的方式进行不同的处理） 如果进一步的进行抽象就得到了我们刚开始所讲的“三剑客”：RpcEnv、RpcEndpoint、RpcEndpointRef RpcEndpointRef发送消息给RpcEnv，RpcEnv查询注册信息将消息路由到指定的RpcEndpoint，RpcEndpoint接收到消息后进行处理（模式匹配的方式） RpcEndpoint的声明周期：constructor -&gt; onStart -&gt; receive* -&gt; onStop 其中receive*包括receive和receiveAndReply 本文我们只是通过一个简单的测试程序分析了Spark Rpc底层的实现，集群中的其它通信（比如Master和Woker的通信）的原理和这个测试类似，只不过具体的发送方式有所不同（包括ask、askWithRetry等），而且远程发消息的时候使用了OutBox和NIO等相关的内容，感兴趣的朋友可以对源码进行详细的阅读，本文不一一说明，目的就是通过简单的测试理解大致流程，不再为“Spark Rpc到底是什么”而纠结，一句话总结：Spark Rpc就是Spark中对分布式消息通信系统的高度抽象。 本文参考和拓展阅读： spark源码 Netty官方网站 Java NIO Tutorial 站内博客未经特殊说明皆为原创，欢迎转载，转载请注明出处、作者，谢谢！","categories":[{"name":"大数据","slug":"bigdata","permalink":"http://www.sun4lower.cn/categories/bigdata/"},{"name":"spark","slug":"bigdata/spark","permalink":"http://www.sun4lower.cn/categories/bigdata/spark/"},{"name":"spark-core","slug":"bigdata/spark/sparkc","permalink":"http://www.sun4lower.cn/categories/bigdata/spark/sparkc/"}],"tags":[{"name":"通信机制","slug":"event","permalink":"http://www.sun4lower.cn/tags/event/"},{"name":"大数据","slug":"bigdata","permalink":"http://www.sun4lower.cn/tags/bigdata/"},{"name":"Netty","slug":"netty","permalink":"http://www.sun4lower.cn/tags/netty/"},{"name":"RPC","slug":"prc","permalink":"http://www.sun4lower.cn/tags/prc/"},{"name":"spark","slug":"spark","permalink":"http://www.sun4lower.cn/tags/spark/"},{"name":"spark-core","slug":"sparkc","permalink":"http://www.sun4lower.cn/tags/sparkc/"}]},{"title":"浅显易懂之线程模型的演变","slug":"event-threadmodel","date":"2017-02-22T09:49:24.000Z","updated":"2017-02-22T13:36:07.000Z","comments":true,"path":"2017/02/22/event-threadmodel/","link":"","permalink":"http://www.sun4lower.cn/2017/02/22/event-threadmodel/","excerpt":"","text":"本文旨在通过一个实际工作中例子让大家理解线程模型的演变，从而对 Netty 的模型有一个粗略的印象，面向的是想初步了解 Netty 原理的读者，而并不关心具体的执行细节和相关术语的描述。 单线程单线程映射到我们的实际工作中就是由一个人完成所有的工作，如下图所示： A 自己独立的完成全部的Job 多线程多线程映射到我们的工作中就是多个人共同协作完成工作，如下图所示： A、B、C 三人工作完成工作，每个人会分到具体的工作去执行，较之单线程，执行效率提高。 线程池多个 Worker（A、B、C等）已经准备好去完成即将到来的Job，当Job 1过来的时候，会从线程池中选择一个线程也就是Worker（A）来完成这项任务，完成之后A仍然要回到线程池中，等待下一个工作的到来。 Reactor单线程模型Reactor 的单线程模型映射到实际工作中如下图所示： 我们有一个Boss来接收具体的Job，然后Boss将具体接收到的Job分配给已经准备好的Worker，交给具体的Worker来完成最终的Job，但是如果Job非常多的时候，Boss的压力就会越来越大，所以Boss成为了性能的瓶颈，而下面提到的Reactor多线程模型就是为了解决这个问题而产生的。 Reactor多线程模型为了完善Reactor单线程模型，Reactor多线程模型进行了优化： 和Reactor单线程模型相比，Reactor多线程模型增加了一个从Manager pool选择Manager(相当于项目经理)的过程，即通过Manager来帮助Boss分配具体的Job给Worker，例如图中选择了M1，那么M1就会去完成选择Worker的工作，虚线代表选择了M2或者M3。 Netty的具体实现就类似于Reactor的多线程模型，而Spark现在Rpc的底层就是通过Netty来实现的。 至此本文的目的已经达到，如果想要更加详细的了解Netty的具体实现细节和NIO相关的知识可以参考如下文章： Netty系列之Netty线程模型 并发编程网有关Netty的部分 Netty官方网站 Java NIO Tutorial 站内博客未经特殊说明皆为原创，欢迎转载，转载请注明出处、作者，谢谢！","categories":[{"name":"大数据","slug":"bigdata","permalink":"http://www.sun4lower.cn/categories/bigdata/"},{"name":"通信机制","slug":"bigdata/event","permalink":"http://www.sun4lower.cn/categories/bigdata/event/"}],"tags":[{"name":"通信机制","slug":"event","permalink":"http://www.sun4lower.cn/tags/event/"},{"name":"Netty","slug":"netty","permalink":"http://www.sun4lower.cn/tags/netty/"},{"name":"多线程","slug":"多线程","permalink":"http://www.sun4lower.cn/tags/多线程/"}]},{"title":"Hello World","slug":"hello-world","date":"2017-02-19T04:52:30.000Z","updated":"2017-02-20T03:19:14.000Z","comments":true,"path":"2017/02/19/hello-world/","link":"","permalink":"http://www.sun4lower.cn/2017/02/19/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server 123public static void main(String[] args)&#123; System.out.print(\"hello world\")&#125; 12def sum(a: Int, b: Int): Int = a + bprintln(\"hello world\") More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment hello world","categories":[{"name":"大数据","slug":"bigdata","permalink":"http://www.sun4lower.cn/categories/bigdata/"},{"name":"spark","slug":"bigdata/spark","permalink":"http://www.sun4lower.cn/categories/bigdata/spark/"},{"name":"spark-core","slug":"bigdata/spark/sparkc","permalink":"http://www.sun4lower.cn/categories/bigdata/spark/sparkc/"}],"tags":[{"name":"大数据","slug":"bigdata","permalink":"http://www.sun4lower.cn/tags/bigdata/"},{"name":"spark-core","slug":"sparkc","permalink":"http://www.sun4lower.cn/tags/sparkc/"},{"name":"性能调优","slug":"perf","permalink":"http://www.sun4lower.cn/tags/perf/"}]}]}